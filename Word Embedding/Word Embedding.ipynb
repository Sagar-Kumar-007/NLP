{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cosine Similarity and Cosine Distance:***<br>\n",
    "Cosine similarity and Cosine Distance is widely used in Recommendation systems. Suppose you have two words p and q. If the distance between the two words is increased then the similarity between them is decreased. Hence, **Cosine Similarity is Inversely Proportional to Cosine Distance.***\n",
    "### [1-(Cosine Similarity)] = (Cosine Distance)<br>\n",
    "*Where, Cosine Similarity = Cos(angle between the vectors p and q)*<br>\n",
    "Hence, when the angle between the words is 90 deg, there is no similarity between the words. If the angle is 0 degrees, then the words are similar to a maximum extent. If the words are contrasting, then the value is -1 (180 degrees). Hence, the values of the Cosine Similarity lies between -1 and +1.<br>\n",
    "Ex: Consider that we are building a Movie Recommendation System. We have watched one movie and based on that our model will recommend new movies to us. If our first movie was Avengers (Genre: Action) then the feature for this will be leaning towards action. Now, consider our new movie to be of comedy genre. This movie will be leaning towards comedy. Since, the angle between the action and comedy feature is 90 degrees, the second movie would not be recommended to us. If our second movie was also an action movie, it will also lean towards the action genre and hence, the angle would be zero and the cosine similarity will be 1. Hence, this movie will be recommended to us.<br>\n",
    "<img src='b.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Word Embedding:***<br>\n",
    "To overcome the disadvantages of Bag Of Words and TF-IDF, we have come over a concept called Word Embedding.Word Embedding can be of two types:<br>\n",
    "1. Word2Vec\n",
    "2. Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Word Embedding:***<br>\n",
    "You know that one cannot show the similarity between the words when one uses BOW (Count Vectorizer) (similar to one-hot encoding and hence it is called a sparse matrix) and TF-IDF to convert the words into vectors. There is also a problem of increase in dimensionality. Suppose that there are about 10,000 words (**here, vocabulary size=10,000**) then your dimensions will be 10,000 which is very large and hence training process will become difficult. To overcome these issues, we use Word Embedding technique.<br>\n",
    "There is a term in Word Embedding called as Feature Representation. In Feature Representation, we create the vectors of the words based on the features. Words that are similar w.r.t the feature will have similar vector coefficients.\n",
    "<br><img src='a.jpg'><br>\n",
    "In the above image, you can see that Boy is given '-1' and girl is given '+1' w.r.t the feature 'Gender'. This is because boy and girl and contrasting words when it is w.r.t gender. Similarly, King and Queen are given similar values when the feature is considered as Royal. Consider that we have around 300 features (Generally, the number of words is greater than the number of features) and hence the dimensions are reduced with a  certain extent. Hence, Word Embedding's matrix is **Dense with Low Dimensions rather than sparse with high dimensions.** Based on the features, the vectors are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you convert these 300 dimensions into 2 dimensions (say, converting them into a graph to represent the vecors) you will observe that the words that are similar will have have their vectors near to each other and hence can be grouped accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**While embedding the words, parameters like Vocabulary size is important. While using the keras one_hot method, the first step is to convert the words into one_hot encoded matrix according to the vocabulary size. one_hot method will assign the word an index and then that index will have the value as 1 and the others will be zero. The size of the matrix will be that of the vocabulary size. Hence, the output for a sentence will be the indices of the particular words of that sentence. Now, we pass the output into a Embedding layer. Here, we specify a parameter which will specify the number of features you want to take under consideration (known as dimensions). For example: Gender, age,food,.. were the features in our previous example and the number of features were 300. Hence the embedding layer is creating a feature representation of our words. Both, the embedding layer and one_hot method is present in Keras.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Steps to follow to create Word Embeddings:***<br>\n",
    "1. Decide the Vocabulary size\n",
    "2. Convert the sentences to one_hot matrix using the one_hot method from keras.preprocessing.text\n",
    "3. Now we will use padding so that our sentences are of equal length. If you use the parameter is 'pre' then the zeroes will be added in the front. We can use pad_sequences from keras.preprocessing.sequence. You add padding since your one_hot matrix size will be according to the number of words in each sentence. Though the index of each word will be based on the size of the vocabulary dictionary.\n",
    "4. Now create an Embedding layer and set the number of features you want (dimensions). Then use the predict method to convert our padded sentences into featurized vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T11:39:08.109007Z",
     "start_time": "2020-10-28T11:39:08.070337Z"
    }
   },
   "outputs": [],
   "source": [
    "### sentences\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T11:40:12.528816Z",
     "start_time": "2020-10-28T11:40:12.505702Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T11:41:18.745057Z",
     "start_time": "2020-10-28T11:41:18.735940Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our first step is to initialize the vocabulary size. Vocabulary size is basically the size of a dictionary.\n",
    "voc_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T11:42:41.610386Z",
     "start_time": "2020-10-28T11:42:41.590075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3288, 890, 5095]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot('I am Sagar',voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T11:44:54.858863Z",
     "start_time": "2020-10-28T11:44:54.847574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3991, 3707, 7145, 4038],\n",
       " [3991, 3707, 7145, 7488],\n",
       " [3991, 110, 7145, 9504],\n",
       " [3288, 890, 5514, 4039, 6797],\n",
       " [3288, 890, 5514, 4039, 2781],\n",
       " [4797, 3991, 1354, 7145, 131],\n",
       " [495, 6142, 9481, 4039]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hence, you pass the text and the vocabulary size to the one_hot method.\n",
    "# After initializing the vocabulary size, our next step is to convert the sentences into one_hot matrix with indices as output\n",
    "oh_representation=[one_hot(sentence,voc_size) for sentence in sent]\n",
    "oh_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T11:53:11.435213Z",
     "start_time": "2020-10-28T11:53:11.414857Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T11:53:52.766667Z",
     "start_time": "2020-10-28T11:53:52.763324Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T11:56:17.736281Z",
     "start_time": "2020-10-28T11:56:17.715483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 3991 3707 7145 4038]\n",
      " [   0    0    0    0 3991 3707 7145 7488]\n",
      " [   0    0    0    0 3991  110 7145 9504]\n",
      " [   0    0    0 3288  890 5514 4039 6797]\n",
      " [   0    0    0 3288  890 5514 4039 2781]\n",
      " [   0    0    0 4797 3991 1354 7145  131]\n",
      " [   0    0    0    0  495 6142 9481 4039]]\n"
     ]
    }
   ],
   "source": [
    "# We give the maximum length of the sentence while padding\n",
    "sent_length=8\n",
    "embeded_docs=pad_sequences(oh_representation,padding='pre',maxlen=sent_length)\n",
    "print(embeded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T11:56:49.352678Z",
     "start_time": "2020-10-28T11:56:49.344567Z"
    }
   },
   "outputs": [],
   "source": [
    "# You can see that all the zeroes are now at the starting of the arrays and the size is now 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:00:51.087683Z",
     "start_time": "2020-10-28T12:00:45.983620Z"
    }
   },
   "outputs": [],
   "source": [
    "dim=10\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(voc_size,dim,input_length=sent_length,)\n",
    "])\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:00:57.229474Z",
     "start_time": "2020-10-28T12:00:57.206916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 8, 10)             100000    \n",
      "=================================================================\n",
      "Total params: 100,000\n",
      "Trainable params: 100,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:11:55.896112Z",
     "start_time": "2020-10-28T12:11:55.573012Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_represented_vectors=model.predict(embeded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:12:01.616345Z",
     "start_time": "2020-10-28T12:12:01.579567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.0768436e-02, -3.4895707e-02,  1.4324192e-02,  3.4971882e-02,\n",
       "         -3.1082774e-02,  1.1571575e-02, -3.3895634e-02, -8.2213059e-03,\n",
       "          4.5744363e-02,  1.9421551e-02],\n",
       "        [ 2.4482731e-02, -2.4074649e-02, -4.4010174e-02, -2.4653280e-02,\n",
       "         -1.1089850e-02, -1.4554381e-02,  2.0490613e-02, -9.9835284e-03,\n",
       "         -2.7619971e-02, -2.7568985e-02],\n",
       "        [ 3.5532165e-02, -6.7853928e-04, -8.2887299e-03,  4.0812362e-02,\n",
       "          2.4271581e-02, -4.6888839e-02,  2.1128487e-02, -9.7663775e-03,\n",
       "         -9.7282156e-03,  3.1800400e-02],\n",
       "        [ 4.9195532e-02, -6.3156597e-03, -7.1504340e-03, -2.9667331e-02,\n",
       "          3.6560822e-02, -3.8764574e-02,  2.1557320e-02,  3.0009151e-03,\n",
       "         -1.2330785e-03, -2.7504122e-02]],\n",
       "\n",
       "       [[ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.0768436e-02, -3.4895707e-02,  1.4324192e-02,  3.4971882e-02,\n",
       "         -3.1082774e-02,  1.1571575e-02, -3.3895634e-02, -8.2213059e-03,\n",
       "          4.5744363e-02,  1.9421551e-02],\n",
       "        [ 2.4482731e-02, -2.4074649e-02, -4.4010174e-02, -2.4653280e-02,\n",
       "         -1.1089850e-02, -1.4554381e-02,  2.0490613e-02, -9.9835284e-03,\n",
       "         -2.7619971e-02, -2.7568985e-02],\n",
       "        [ 3.5532165e-02, -6.7853928e-04, -8.2887299e-03,  4.0812362e-02,\n",
       "          2.4271581e-02, -4.6888839e-02,  2.1128487e-02, -9.7663775e-03,\n",
       "         -9.7282156e-03,  3.1800400e-02],\n",
       "        [-2.2028744e-02, -1.5789200e-02, -2.7352704e-02, -4.8981249e-02,\n",
       "          2.8362405e-02, -2.0437812e-02, -3.8286816e-02,  1.8451784e-02,\n",
       "         -3.0818209e-03,  1.0585915e-02]],\n",
       "\n",
       "       [[ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.0768436e-02, -3.4895707e-02,  1.4324192e-02,  3.4971882e-02,\n",
       "         -3.1082774e-02,  1.1571575e-02, -3.3895634e-02, -8.2213059e-03,\n",
       "          4.5744363e-02,  1.9421551e-02],\n",
       "        [-3.3164397e-02, -1.3839379e-03,  2.2669125e-02,  7.9039708e-03,\n",
       "          2.0631883e-02,  4.4359449e-02,  3.1117622e-02,  4.1995492e-02,\n",
       "         -2.1593226e-02, -2.8752590e-02],\n",
       "        [ 3.5532165e-02, -6.7853928e-04, -8.2887299e-03,  4.0812362e-02,\n",
       "          2.4271581e-02, -4.6888839e-02,  2.1128487e-02, -9.7663775e-03,\n",
       "         -9.7282156e-03,  3.1800400e-02],\n",
       "        [-1.0998774e-02, -3.2903492e-02, -3.5518788e-02, -2.2704229e-03,\n",
       "         -7.3529705e-03,  3.5510492e-02,  3.3347834e-02,  4.0838864e-02,\n",
       "         -7.2545782e-03, -6.6860802e-03]],\n",
       "\n",
       "       [[ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [-2.3475779e-02,  3.1644132e-02, -1.8372882e-02,  3.6177065e-02,\n",
       "          3.6824588e-02,  2.1514129e-02,  1.0890961e-03,  1.6995225e-02,\n",
       "          8.5172765e-03,  4.7191251e-02],\n",
       "        [-1.9845271e-02,  4.9829260e-03,  1.4888871e-02,  2.6993703e-02,\n",
       "         -3.9679788e-02,  1.9314501e-02, -1.2473486e-02, -2.7536973e-03,\n",
       "         -1.3298474e-02,  3.2760110e-02],\n",
       "        [-3.8990997e-02, -2.9261542e-02, -2.4531543e-02,  5.1855221e-03,\n",
       "          2.5212143e-02,  4.2159025e-02, -7.2023161e-03,  4.7188688e-02,\n",
       "         -3.3889137e-02,  1.6887967e-02],\n",
       "        [ 3.6468197e-02,  1.4985729e-02, -3.6446296e-02,  9.3209147e-03,\n",
       "         -6.8434365e-03, -5.6867227e-03, -3.3078946e-02,  9.3790889e-03,\n",
       "          3.0866746e-02, -2.5013566e-02],\n",
       "        [ 2.9145267e-02,  3.4541871e-02,  2.3134623e-02, -1.9316448e-02,\n",
       "         -3.8990010e-02,  2.2326205e-02, -8.8096149e-03,  9.1598183e-04,\n",
       "          2.5093555e-04,  1.9010331e-02]],\n",
       "\n",
       "       [[ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [-2.3475779e-02,  3.1644132e-02, -1.8372882e-02,  3.6177065e-02,\n",
       "          3.6824588e-02,  2.1514129e-02,  1.0890961e-03,  1.6995225e-02,\n",
       "          8.5172765e-03,  4.7191251e-02],\n",
       "        [-1.9845271e-02,  4.9829260e-03,  1.4888871e-02,  2.6993703e-02,\n",
       "         -3.9679788e-02,  1.9314501e-02, -1.2473486e-02, -2.7536973e-03,\n",
       "         -1.3298474e-02,  3.2760110e-02],\n",
       "        [-3.8990997e-02, -2.9261542e-02, -2.4531543e-02,  5.1855221e-03,\n",
       "          2.5212143e-02,  4.2159025e-02, -7.2023161e-03,  4.7188688e-02,\n",
       "         -3.3889137e-02,  1.6887967e-02],\n",
       "        [ 3.6468197e-02,  1.4985729e-02, -3.6446296e-02,  9.3209147e-03,\n",
       "         -6.8434365e-03, -5.6867227e-03, -3.3078946e-02,  9.3790889e-03,\n",
       "          3.0866746e-02, -2.5013566e-02],\n",
       "        [-4.4091072e-02, -1.1371434e-02, -2.5255322e-02,  1.3051834e-02,\n",
       "          4.1466895e-02,  3.9818671e-02,  4.7971383e-03, -2.3348523e-02,\n",
       "          4.3303397e-02, -2.7889848e-02]],\n",
       "\n",
       "       [[ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [-5.8116317e-03, -4.9195290e-03,  1.8194858e-02,  1.2263976e-02,\n",
       "          2.2138726e-02, -4.0592838e-02,  8.2180388e-03, -4.0225018e-02,\n",
       "         -3.0928386e-02, -6.9969073e-03],\n",
       "        [ 1.0768436e-02, -3.4895707e-02,  1.4324192e-02,  3.4971882e-02,\n",
       "         -3.1082774e-02,  1.1571575e-02, -3.3895634e-02, -8.2213059e-03,\n",
       "          4.5744363e-02,  1.9421551e-02],\n",
       "        [-2.8792584e-02,  4.5414541e-02,  4.8446629e-02, -2.3431862e-02,\n",
       "         -4.9633134e-02, -2.1443868e-02,  1.3736550e-02,  4.7910977e-02,\n",
       "          2.5739703e-02,  3.5730314e-02],\n",
       "        [ 3.5532165e-02, -6.7853928e-04, -8.2887299e-03,  4.0812362e-02,\n",
       "          2.4271581e-02, -4.6888839e-02,  2.1128487e-02, -9.7663775e-03,\n",
       "         -9.7282156e-03,  3.1800400e-02],\n",
       "        [-4.2258706e-02, -7.8586712e-03,  4.3305431e-02, -3.6048960e-02,\n",
       "         -9.5028505e-03, -1.7745532e-02,  4.2789690e-03,  7.4435957e-03,\n",
       "          3.3685181e-02,  1.0559749e-02]],\n",
       "\n",
       "       [[ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [ 1.9293156e-02,  3.8332593e-02,  2.2653710e-02,  2.6543166e-02,\n",
       "         -4.9123466e-02,  2.0348396e-02, -2.6128352e-02,  3.3831704e-02,\n",
       "          2.9787149e-02,  4.4139709e-02],\n",
       "        [-3.0036187e-02,  1.1075567e-02,  2.2753548e-02, -6.0401857e-05,\n",
       "          4.7182944e-02,  9.7446330e-03,  2.3840372e-02,  4.9699035e-02,\n",
       "         -4.9392581e-02,  2.1037687e-02],\n",
       "        [ 9.7130761e-03, -1.0214053e-02, -2.6306832e-02,  2.8664257e-02,\n",
       "         -1.9180393e-02,  6.1132014e-05, -3.0001391e-02,  4.0127162e-02,\n",
       "          1.5557084e-02, -2.3712600e-02],\n",
       "        [-1.3451435e-02, -3.1259194e-02,  3.1905603e-02, -2.3495033e-04,\n",
       "         -1.3527162e-03,  2.7758408e-02,  2.0151589e-02,  2.4043251e-02,\n",
       "          2.7546477e-02, -9.5824152e-04],\n",
       "        [ 3.6468197e-02,  1.4985729e-02, -3.6446296e-02,  9.3209147e-03,\n",
       "         -6.8434365e-03, -5.6867227e-03, -3.3078946e-02,  9.3790889e-03,\n",
       "          3.0866746e-02, -2.5013566e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_represented_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:12:21.223363Z",
     "start_time": "2020-10-28T12:12:21.207992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0, 3991, 3707, 7145, 4038])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:12:09.243849Z",
     "start_time": "2020-10-28T12:12:09.233388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01929316,  0.03833259,  0.02265371,  0.02654317, -0.04912347,\n",
       "         0.0203484 , -0.02612835,  0.0338317 ,  0.02978715,  0.04413971],\n",
       "       [ 0.01929316,  0.03833259,  0.02265371,  0.02654317, -0.04912347,\n",
       "         0.0203484 , -0.02612835,  0.0338317 ,  0.02978715,  0.04413971],\n",
       "       [ 0.01929316,  0.03833259,  0.02265371,  0.02654317, -0.04912347,\n",
       "         0.0203484 , -0.02612835,  0.0338317 ,  0.02978715,  0.04413971],\n",
       "       [ 0.01929316,  0.03833259,  0.02265371,  0.02654317, -0.04912347,\n",
       "         0.0203484 , -0.02612835,  0.0338317 ,  0.02978715,  0.04413971],\n",
       "       [ 0.01076844, -0.03489571,  0.01432419,  0.03497188, -0.03108277,\n",
       "         0.01157157, -0.03389563, -0.00822131,  0.04574436,  0.01942155],\n",
       "       [ 0.02448273, -0.02407465, -0.04401017, -0.02465328, -0.01108985,\n",
       "        -0.01455438,  0.02049061, -0.00998353, -0.02761997, -0.02756898],\n",
       "       [ 0.03553217, -0.00067854, -0.00828873,  0.04081236,  0.02427158,\n",
       "        -0.04688884,  0.02112849, -0.00976638, -0.00972822,  0.0318004 ],\n",
       "       [ 0.04919553, -0.00631566, -0.00715043, -0.02966733,  0.03656082,\n",
       "        -0.03876457,  0.02155732,  0.00300092, -0.00123308, -0.02750412]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_represented_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:13:37.695200Z",
     "start_time": "2020-10-28T12:13:37.688927Z"
    }
   },
   "outputs": [],
   "source": [
    "# You can see that each word is converted into 10 vectors (showing the similarity between the words and the features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:14:29.057121Z",
     "start_time": "2020-10-28T12:14:29.047685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Since the total number of words are 8, we have a total of 8 arrays for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:14:34.902894Z",
     "start_time": "2020-10-28T12:14:34.893436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_represented_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:15:04.197723Z",
     "start_time": "2020-10-28T12:15:04.180269Z"
    }
   },
   "outputs": [],
   "source": [
    "# 7: sentences.....8: Words in a sentence.......10: features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
